{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_NRlSL9u_0G",
        "outputId": "a68eb569-4b0e-4b55-d5d8-ca9440a853f0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/github/LightGCN_PyTorch/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByvXOOPZvj0N",
        "outputId": "e5ec031e-1bab-4228-fa49-f53390c05249"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/github/LightGCN_PyTorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRJoN17_m-WQ",
        "outputId": "077e506b-6c5a-4dd7-bb4c-19346741042c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.4.0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.4.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/github/LightGCN_PyTorch/code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30eDKD_ZnIvJ",
        "outputId": "e966b936-b177-4c5e-a073-81ab16499062"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/github/LightGCN_PyTorch/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#path = '/content/drive/MyDrive/github/LightGCN/Data/gowalla'\n",
        "#dataset_gowalla = dataloader.Loader(config={'A_split': True, 'A_n_fold': 5}, path=path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaRJUqQSsrip",
        "outputId": "ee101408-5d77-4659-a76f-c667dbc072e2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;30;43mloading [/content/drive/MyDrive/github/LightGCN/Data/gowalla]\u001b[0m\n",
            "810128 interactions for training\n",
            "217242 interactions for testing\n",
            "gowalla Sparsity : 0.0008396216228570436\n",
            "gowalla is ready to go\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9EmDUdyA1nm",
        "outputId": "25f0e616-f1fa-4193-a744-69656e17fd3b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.1-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.1)\n",
            "Collecting protobuf>=4.22.3 (from tensorboardX)\n",
            "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, tensorboardX\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "Successfully installed protobuf-4.23.4 tensorboardX-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run main.py --decay=1e-4 --lr=0.001 --layer=3 --seed=2020 --dataset=\"yelp2018\" --topks=\"[20]\" --recdim=64 --epochs=100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuPeqZKW_yOi",
        "outputId": "59629120-15d8-4016-a75f-8f5af938eb60"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>SEED: 2020\n",
            "\u001b[0;30;43mloading [../data/yelp2018]\u001b[0m\n",
            "1237259 interactions for training\n",
            "324147 interactions for testing\n",
            "yelp2018 Sparsity : 0.0012958757851778647\n",
            "yelp2018 is ready to go\n",
            "===========config================\n",
            "{'A_n_fold': 100,\n",
            " 'A_split': False,\n",
            " 'bigdata': False,\n",
            " 'bpr_batch_size': 2048,\n",
            " 'decay': 0.0001,\n",
            " 'dropout': 0,\n",
            " 'keep_prob': 0.6,\n",
            " 'latent_dim_rec': 64,\n",
            " 'lightGCN_n_layers': 3,\n",
            " 'lr': 0.001,\n",
            " 'multicore': 0,\n",
            " 'pretrain': 0,\n",
            " 'test_u_batch_size': 100}\n",
            "cores for test: 1\n",
            "comment: lgn\n",
            "tensorboard: 1\n",
            "LOAD: 0\n",
            "Weight path: ./checkpoints\n",
            "Test Topks: [20]\n",
            "using bpr loss\n",
            "===========end===================\n",
            "\u001b[0;30;43muse NORMAL distribution initilizer\u001b[0m\n",
            "loading adjacency matrix\n",
            "successfully loaded...\n",
            "don't split the matrix\n",
            "lgn is already to go(dropout:0)\n",
            "load and save to /content/drive/MyDrive/github/LightGCN_PyTorch/code/checkpoints/lgn-yelp2018-3-64.pth.tar\n",
            "\u001b[0;30;43m[TEST]\u001b[0m\n",
            "{'precision': array([0.00027788]), 'recall': array([0.00052693]), 'ndcg': array([0.00044859])}\n",
            "EPOCH[1/100] loss0.400-|Sample:20.63|\n",
            "EPOCH[2/100] loss0.162-|Sample:19.14|\n",
            "EPOCH[3/100] loss0.147-|Sample:18.76|\n",
            "EPOCH[4/100] loss0.138-|Sample:20.45|\n",
            "EPOCH[5/100] loss0.131-|Sample:18.53|\n",
            "EPOCH[6/100] loss0.123-|Sample:20.35|\n",
            "EPOCH[7/100] loss0.116-|Sample:19.07|\n",
            "EPOCH[8/100] loss0.111-|Sample:19.07|\n",
            "EPOCH[9/100] loss0.106-|Sample:20.28|\n",
            "EPOCH[10/100] loss0.103-|Sample:18.30|\n",
            "\u001b[0;30;43m[TEST]\u001b[0m\n",
            "{'precision': array([0.01831975]), 'recall': array([0.04046113]), 'ndcg': array([0.03232298])}\n",
            "EPOCH[11/100] loss0.100-|Sample:18.36|\n",
            "EPOCH[12/100] loss0.096-|Sample:19.63|\n",
            "EPOCH[13/100] loss0.094-|Sample:20.38|\n",
            "EPOCH[14/100] loss0.092-|Sample:18.21|\n",
            "EPOCH[15/100] loss0.090-|Sample:19.89|\n",
            "EPOCH[16/100] loss0.087-|Sample:18.89|\n",
            "EPOCH[17/100] loss0.085-|Sample:20.36|\n",
            "EPOCH[18/100] loss0.083-|Sample:19.91|\n",
            "EPOCH[19/100] loss0.081-|Sample:18.99|\n",
            "EPOCH[20/100] loss0.079-|Sample:20.14|\n",
            "\u001b[0;30;43m[TEST]\u001b[0m\n",
            "{'precision': array([0.02002337]), 'recall': array([0.04427176]), 'ndcg': array([0.03550175])}\n",
            "EPOCH[21/100] loss0.078-|Sample:19.13|\n",
            "EPOCH[22/100] loss0.076-|Sample:20.50|\n",
            "EPOCH[23/100] loss0.074-|Sample:18.83|\n",
            "EPOCH[24/100] loss0.073-|Sample:20.46|\n",
            "EPOCH[25/100] loss0.072-|Sample:19.06|\n",
            "EPOCH[26/100] loss0.070-|Sample:19.88|\n",
            "EPOCH[27/100] loss0.070-|Sample:20.88|\n",
            "EPOCH[28/100] loss0.068-|Sample:18.72|\n",
            "EPOCH[29/100] loss0.067-|Sample:20.57|\n",
            "EPOCH[30/100] loss0.066-|Sample:18.60|\n",
            "\u001b[0;30;43m[TEST]\u001b[0m\n",
            "{'precision': array([0.02102596]), 'recall': array([0.04664742]), 'ndcg': array([0.03760802])}\n",
            "EPOCH[31/100] loss0.065-|Sample:20.73|\n",
            "EPOCH[32/100] loss0.064-|Sample:18.74|\n",
            "EPOCH[33/100] loss0.063-|Sample:20.35|\n",
            "EPOCH[34/100] loss0.062-|Sample:20.65|\n",
            "EPOCH[35/100] loss0.061-|Sample:18.55|\n",
            "EPOCH[36/100] loss0.060-|Sample:20.24|\n",
            "EPOCH[37/100] loss0.059-|Sample:18.63|\n",
            "EPOCH[38/100] loss0.059-|Sample:19.56|\n",
            "EPOCH[39/100] loss0.057-|Sample:19.47|\n",
            "EPOCH[40/100] loss0.057-|Sample:18.99|\n",
            "\u001b[0;30;43m[TEST]\u001b[0m\n",
            "{'precision': array([0.02205223]), 'recall': array([0.0490835]), 'ndcg': array([0.03949515])}\n",
            "EPOCH[41/100] loss0.056-|Sample:19.05|\n",
            "EPOCH[42/100] loss0.055-|Sample:20.76|\n",
            "EPOCH[43/100] loss0.054-|Sample:20.16|\n",
            "EPOCH[44/100] loss0.054-|Sample:19.09|\n",
            "EPOCH[45/100] loss0.053-|Sample:20.25|\n",
            "EPOCH[46/100] loss0.053-|Sample:18.91|\n",
            "EPOCH[47/100] loss0.052-|Sample:19.66|\n",
            "EPOCH[48/100] loss0.051-|Sample:20.09|\n",
            "EPOCH[49/100] loss0.051-|Sample:18.96|\n",
            "EPOCH[50/100] loss0.050-|Sample:19.80|\n",
            "\u001b[0;30;43m[TEST]\u001b[0m\n",
            "{'precision': array([0.02278641]), 'recall': array([0.05100451]), 'ndcg': array([0.04095051])}\n",
            "EPOCH[51/100] loss0.050-|Sample:19.00|\n",
            "EPOCH[52/100] loss0.049-|Sample:20.09|\n",
            "EPOCH[53/100] loss0.049-|Sample:18.42|\n",
            "EPOCH[54/100] loss0.048-|Sample:20.29|\n",
            "EPOCH[55/100] loss0.048-|Sample:18.05|\n",
            "EPOCH[56/100] loss0.046-|Sample:18.44|\n",
            "EPOCH[57/100] loss0.046-|Sample:19.54|\n",
            "EPOCH[58/100] loss0.046-|Sample:17.85|\n",
            "EPOCH[59/100] loss0.045-|Sample:19.87|\n",
            "EPOCH[60/100] loss0.045-|Sample:17.92|\n",
            "\u001b[0;30;43m[TEST]\u001b[0m\n",
            "{'precision': array([0.02357269]), 'recall': array([0.05269359]), 'ndcg': array([0.0424328])}\n",
            "EPOCH[61/100] loss0.044-|Sample:18.48|\n",
            "EPOCH[62/100] loss0.044-|Sample:18.28|\n",
            "EPOCH[63/100] loss0.043-|Sample:18.67|\n",
            "EPOCH[64/100] loss0.043-|Sample:18.33|\n",
            "EPOCH[65/100] loss0.043-|Sample:19.67|\n",
            "EPOCH[66/100] loss0.042-|Sample:18.00|\n",
            "EPOCH[67/100] loss0.042-|Sample:20.02|\n",
            "EPOCH[68/100] loss0.041-|Sample:18.04|\n",
            "EPOCH[69/100] loss0.041-|Sample:19.03|\n",
            "EPOCH[70/100] loss0.041-|Sample:17.98|\n",
            "\u001b[0;30;43m[TEST]\u001b[0m\n",
            "{'precision': array([0.02413635]), 'recall': array([0.05413176]), 'ndcg': array([0.04356368])}\n",
            "EPOCH[71/100] loss0.040-|Sample:19.79|\n",
            "EPOCH[72/100] loss0.040-|Sample:18.24|\n",
            "EPOCH[73/100] loss0.040-|Sample:19.57|\n",
            "EPOCH[74/100] loss0.039-|Sample:18.27|\n",
            "EPOCH[75/100] loss0.039-|Sample:18.74|\n",
            "EPOCH[76/100] loss0.039-|Sample:18.95|\n",
            "EPOCH[77/100] loss0.039-|Sample:18.78|\n",
            "EPOCH[78/100] loss0.038-|Sample:19.90|\n",
            "EPOCH[79/100] loss0.038-|Sample:18.43|\n",
            "EPOCH[80/100] loss0.037-|Sample:19.45|\n",
            "\u001b[0;30;43m[TEST]\u001b[0m\n",
            "{'precision': array([0.02477264]), 'recall': array([0.05576558]), 'ndcg': array([0.04492723])}\n",
            "EPOCH[81/100] loss0.037-|Sample:18.73|\n",
            "EPOCH[82/100] loss0.036-|Sample:19.71|\n",
            "EPOCH[83/100] loss0.037-|Sample:18.33|\n",
            "EPOCH[84/100] loss0.036-|Sample:20.06|\n",
            "EPOCH[85/100] loss0.036-|Sample:18.19|\n",
            "EPOCH[86/100] loss0.036-|Sample:18.95|\n",
            "EPOCH[87/100] loss0.036-|Sample:20.08|\n",
            "EPOCH[88/100] loss0.035-|Sample:18.17|\n",
            "EPOCH[89/100] loss0.035-|Sample:19.75|\n",
            "EPOCH[90/100] loss0.035-|Sample:18.09|\n",
            "\u001b[0;30;43m[TEST]\u001b[0m\n",
            "{'precision': array([0.02499053]), 'recall': array([0.05613972]), 'ndcg': array([0.04546331])}\n",
            "EPOCH[91/100] loss0.035-|Sample:19.76|\n",
            "EPOCH[92/100] loss0.034-|Sample:18.17|\n",
            "EPOCH[93/100] loss0.034-|Sample:19.79|\n",
            "EPOCH[94/100] loss0.034-|Sample:18.42|\n",
            "EPOCH[95/100] loss0.034-|Sample:19.30|\n",
            "EPOCH[96/100] loss0.033-|Sample:18.26|\n",
            "EPOCH[97/100] loss0.033-|Sample:19.00|\n",
            "EPOCH[98/100] loss0.033-|Sample:19.60|\n",
            "EPOCH[99/100] loss0.033-|Sample:18.52|\n",
            "EPOCH[100/100] loss0.032-|Sample:19.81|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load pretrained model\n",
        "import model\n",
        "import dataloader\n",
        "import world"
      ],
      "metadata": {
        "id": "FeGltQ-TWBnj"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_file = '/content/drive/MyDrive/github/LightGCN_PyTorch/code/checkpoints/lgn-yelp2018-3-64.pth.tar'"
      ],
      "metadata": {
        "id": "SI9n4Wp_WLKq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = dataloader.Loader(path+'amazon-book')\n",
        "path = '/content/drive/MyDrive/github/LightGCN/Data/yelp2018'\n",
        "dataset = dataloader.Loader(config={'A_split': True, 'A_n_fold': 5}, path=path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poQOn92UnddJ",
        "outputId": "19ec41d1-4aa2-4405-e416-7cf5049adc46"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;30;43mloading [/content/drive/MyDrive/github/LightGCN/Data/yelp2018]\u001b[0m\n",
            "1237259 interactions for training\n",
            "324147 interactions for testing\n",
            "yelp2018 Sparsity : 0.0012958757851778647\n",
            "yelp2018 is ready to go\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.getSparseGraph()[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ezlbievfuooo",
        "outputId": "5b26519d-f13b-4ae2-c033-c6bc9038486b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading adjacency matrix\n",
            "torch.Size([13943, 69716])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "world.config['pretrain'] = 1"
      ],
      "metadata": {
        "id": "M1n7wdlNrNzu"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save user and item embeddings to separate files\n",
        "\n",
        "#np.save(user_emb_file, Recmodel.embedding_user.weight.data.cpu().numpy())\n",
        "#np.save(item_emb_file, Recmodel.embedding_item.weight.data.cpu().numpy())\n",
        "\n",
        "#user_emb_file = \"user_emb.npy\"\n",
        "#item_emb_file = \"item_emb.npy\"\n",
        "\n",
        "#world.config['user_emb'] = np.load(user_emb_file)\n",
        "#world.config['item_emb'] = np.load(item_emb_file)\n"
      ],
      "metadata": {
        "id": "d4RsAlirtdvH"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "# Create a folder to store the embeddings\n",
        "embedding_folder = \"embeddings\"\n",
        "os.makedirs(embedding_folder, exist_ok=True)\n",
        "\n",
        "# Get the user and item embeddings from the trained model\n",
        "user_embeddings = Recmodel.embedding_user.weight.data.cpu().numpy()\n",
        "item_embeddings = Recmodel.embedding_item.weight.data.cpu().numpy()\n",
        "\n",
        "# Save the embeddings to files\n",
        "user_emb_file = os.path.join(embedding_folder, \"user_embeddings.npy\")\n",
        "item_emb_file = os.path.join(embedding_folder, \"item_embeddings.npy\")\n",
        "np.save(user_emb_file, user_embeddings)\n",
        "np.save(item_emb_file, item_embeddings)\n"
      ],
      "metadata": {
        "id": "Ka7gg-CYwNEJ"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the user and item embeddings from files\n",
        "\n",
        "user_embeddings = np.load(user_emb_file)\n",
        "item_embeddings = np.load(item_emb_file)\n",
        "\n",
        "world.config['user_emb'] = np.load(user_emb_file)\n",
        "world.config['item_emb'] = np.load(item_emb_file)"
      ],
      "metadata": {
        "id": "iNic62VrxOlG"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Recmodel_load = model.LightGCN(world.config,dataset)\n",
        "\n",
        "Recmodel_load.load_state_dict(torch.load(weight_file, map_location=torch.device('cpu')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTT48PfKcDKe",
        "outputId": "9a3b37f7-c456-4041-fb15-6682ef5e4716"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use pretarined data\n",
            "loading adjacency matrix\n",
            "lgn is already to go(dropout:0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "world.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OpPbKTqrqRI",
        "outputId": "cdf32ffe-dde1-48ee-e5c0-4d87f1689d7d"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bpr_batch_size': 2048,\n",
              " 'latent_dim_rec': 64,\n",
              " 'lightGCN_n_layers': 3,\n",
              " 'dropout': 0,\n",
              " 'keep_prob': 0.6,\n",
              " 'A_n_fold': 100,\n",
              " 'test_u_batch_size': 100,\n",
              " 'multicore': 0,\n",
              " 'lr': 0.001,\n",
              " 'decay': 0.0001,\n",
              " 'pretrain': 1,\n",
              " 'A_split': False,\n",
              " 'bigdata': False,\n",
              " 'user_emb': array([[-1.4755441 ,  1.9496558 , -0.23540732, ..., -0.9579076 ,\n",
              "          0.03934332, -1.6575844 ],\n",
              "        [ 0.41487688, -0.03457997, -0.4186617 , ..., -0.46712428,\n",
              "         -0.26577732,  0.47366437],\n",
              "        [-0.8878664 ,  0.00396788, -0.25164598, ...,  0.4763229 ,\n",
              "         -0.91850364, -0.33945835],\n",
              "        ...,\n",
              "        [ 0.2872131 ,  0.393385  , -0.5646815 , ..., -1.3087955 ,\n",
              "          1.0514622 , -0.3352326 ],\n",
              "        [ 0.61467314,  0.31270343, -0.9486345 , ..., -2.3770318 ,\n",
              "          1.9729568 ,  0.5409625 ],\n",
              "        [-1.659197  ,  0.21919179,  1.666641  , ...,  0.23477043,\n",
              "          0.9548086 , -0.57835436]], dtype=float32),\n",
              " 'item_emb': array([[-0.9502222 , -0.9813624 ,  0.65437907, ...,  0.83292323,\n",
              "         -0.35116833, -0.9483467 ],\n",
              "        [-0.92500436,  0.6825007 , -0.7605772 , ..., -0.08185382,\n",
              "         -0.16875459, -0.5371803 ],\n",
              "        [-0.5596525 ,  0.96116537, -0.36965626, ..., -0.1601879 ,\n",
              "         -0.07567844, -0.18396899],\n",
              "        ...,\n",
              "        [-0.21993595, -0.25593612, -0.9736494 , ...,  0.24796109,\n",
              "         -1.0886458 ,  0.14260182],\n",
              "        [-0.7457257 , -0.8601189 ,  0.39810902, ...,  0.37183204,\n",
              "          0.26614696,  0.8147047 ],\n",
              "        [-0.26837403, -0.3136773 , -0.44665012, ..., -0.6681962 ,\n",
              "          0.31954148, -0.38691354]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X9jKQ10yrQqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Recmodel_load.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MeBH9pVlSVp",
        "outputId": "59e25aaf-cfab-4779-ebe4-b02aedaeb324"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LightGCN(\n",
              "  (embedding_user): Embedding(31668, 64)\n",
              "  (embedding_item): Embedding(38048, 64)\n",
              "  (f): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#user_embeddings = Recmodel.embedding_user.weight.data\n",
        "#item_embeddings = Recmodel.embedding_item.weight.data"
      ],
      "metadata": {
        "id": "QWKjT8sURbi2"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaOfZ_phSMSP",
        "outputId": "e18bf256-b660-4910-e4a5-8b2fb0ac9a94"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([31668, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "item_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feAQ6vfsSVfS",
        "outputId": "ce82f6dc-1a53-4df8-f6fc-d3eb1b250729"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([38048, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Recmodel_load.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV01QGoCVNSz",
        "outputId": "cdd9975e-3dba-45a2-9a20-9aebdc09d0ac"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LightGCN(\n",
              "  (embedding_user): Embedding(31668, 64)\n",
              "  (embedding_item): Embedding(38048, 64)\n",
              "  (f): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "users = torch.tensor([15,29,198,477])  # Replace user_id1, user_id2, ... with actual user IDs\n",
        "ratings = Recmodel.getUsersRating(users)"
      ],
      "metadata": {
        "id": "XlDDp5_IZ2It"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Procedure\n",
        "for epoch in range(world.TRAIN_epochs):\n",
        "        start = time.time()\n",
        "        if epoch %10 == 0:\n",
        "            cprint(\"[TEST]\")\n",
        "            Procedure.Test(dataset, Recmodel_load, epoch, w, world.config['multicore'])\n",
        "        output_information = Procedure.BPR_train_original(dataset, Recmodel_load, bpr, epoch, neg_k=Neg_k,w=w)\n",
        "        print(f'EPOCH[{epoch+1}/{world.TRAIN_epochs}] {output_information}')\n",
        "        torch.save(Recmodel.state_dict(), weight_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "GSYODgRNqDmC",
        "outputId": "20782903-de83-4577-9b28-5b41986731fc"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;30;43m[TEST]\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-031ab7a75221>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mcprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[TEST]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mProcedure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRecmodel_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'multicore'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0moutput_information\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcedure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBPR_train_original\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRecmodel_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNeg_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'EPOCH[{epoch+1}/{world.TRAIN_epochs}] {output_information}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/github/LightGCN_PyTorch/code/Procedure.py\u001b[0m in \u001b[0;36mTest\u001b[0;34m(dataset, Recmodel, epoch, w, multicore)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mbatch_users_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_users_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetUsersRating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_users_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0;31m#rating = rating.cpu()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mexclude_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/github/LightGCN_PyTorch/code/model.py\u001b[0m in \u001b[0;36mgetUsersRating\u001b[0;34m(self, users)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetUsersRating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mall_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0musers_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_users\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mitems_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/github/LightGCN_PyTorch/code/model.py\u001b[0m in \u001b[0;36mcomputer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mall_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mside_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0mall_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_droped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0membs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: _sparse_mm(): argument 'sparse' (position 1) must be Tensor, not list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "users = torch.tensor([15,29,198,477])  # Replace user_id1, user_id2, ... with actual user IDs\n",
        "ratings = Recmodel_load.getUsersRating(users)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "ET13rsTikA8y",
        "outputId": "1a797996-cae0-43d2-ec1c-96a2fb85d2b7"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-cb377342e3da>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0musers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m198\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m477\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace user_id1, user_id2, ... with actual user IDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecmodel_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetUsersRating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/drive/MyDrive/github/LightGCN_PyTorch/code/model.py\u001b[0m in \u001b[0;36mgetUsersRating\u001b[0;34m(self, users)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetUsersRating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mall_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0musers_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_users\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mitems_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/github/LightGCN_PyTorch/code/model.py\u001b[0m in \u001b[0;36mcomputer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mall_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mside_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0mall_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_droped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0membs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: _sparse_mm(): argument 'sparse' (position 1) must be Tensor, not list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gzGyRvJaM2y",
        "outputId": "23b81de6-f655-4885-9900-82ddd44211dd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1171, 0.9999, 1.0000,  ..., 0.5883, 0.7034, 0.6407],\n",
              "        [1.0000, 0.8707, 0.7832,  ..., 0.1627, 0.2397, 0.4612],\n",
              "        [1.0000, 0.8773, 0.8904,  ..., 0.2617, 0.3160, 0.5294],\n",
              "        [0.1289, 0.9112, 0.9485,  ..., 0.7539, 0.5671, 0.7961]],\n",
              "       device='cuda:0', grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_ratings, top_indices = torch.topk(ratings, 20, dim=1, largest=True)"
      ],
      "metadata": {
        "id": "Q8Ue2IIeac4Z"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eos5w5Q4agHs",
        "outputId": "d78687e3-14dc-431b-f31c-059d38e018d0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  932,  7270,   949,     2,  8129,  4983,  3410,  4048,  4039,  8136,\n",
              "           947,  3407,  4986,  8119,  4984,   951,  3401,   953,  3405,  4059],\n",
              "        [  786,    11,   649,    12,  2014,    87,   710,   827,    81,     0,\n",
              "           769,  1716,   657,   774,   868,  1532,     8,  1540,  4497,  1025],\n",
              "        [  786,    87,   649,    11,   868,  2014,    81,  4497,   657,     0,\n",
              "           710,   774,     8,  1532,    82,    12,    93,   721,    13,    15],\n",
              "        [ 5883,  8106, 12220,  8093,   749,  6351,  6356,  3436,  2645,  6316,\n",
              "          5886,  9031,  2649,  6335,  2651,  9301,  6348,  8523,  4066,  2660]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gcoj3Yrkyvdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAN"
      ],
      "metadata": {
        "id": "sPzAHvMmywuj"
      }
    }
  ]
}